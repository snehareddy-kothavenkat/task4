# -*- coding: utf-8 -*-
"""task4

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UGVTTv1u27zlBdvfa8JsJbSJVQ-cCNAE
"""

from keras.applications import VGG16

vgg16 = VGG16(weights = 'imagenet',
       include_top = False, 
        input_shape =(224,224,3))

for layer in vgg16.layers:
  layer.trainable = False

for (i,layer) in enumerate(vgg16.layers):
  print(i,layer.__class__.__name__,layer.trainable)

def create_model(bottom_model,labels):
  top_model = bottom_model.output
  top_model = GlobalAveragePooling2D()(top_model)
  top_model = Dense(1024, activation = 'relu')(top_model)  
  top_model = Dense(1024, activation = 'relu')(top_model)  
  top_model = Dense(512, activation = 'relu')(top_model)  
  top_model = Dense(labels, activation = 'softmax')(top_model)
  return top_model

from keras.layers import GlobalAveragePooling2D,Dense
from keras.models import Model

class_labels = 2
neural_network = create_model(vgg16, class_labels)

model = Model(inputs = vgg16.input, outputs = neural_network)
model.summary()

from keras.preprocessing.image import ImageDataGenerator

train_directory = '/content/drive/My Drive/dataset/train/'
val_directory = '/content/drive/My Drive/dataset/val/'

train_data_generation = ImageDataGenerator(
                 rescale = 1./255,
                 rotation_range = 45,
                 height_shift_range = 0.3,
                 width_shift_range = 0.3,
                 horizontal_flip = True,
                 fill_mode = 'nearest'
)

val_data_generation = ImageDataGenerator(
                rescale = 1./255
)

batch_size = 32

generated_train_images = train_data_generation.flow_from_directory(
                   train_directory,
                   target_size = (224,224),
                   batch_size = batch_size,
                   class_mode = 'categorical'
)
generated_val_images = val_data_generation.flow_from_directory(
                   val_directory,
                   target_size = (224,224),
                   batch_size = batch_size,
                   class_mode = 'categorical'
)

from keras.optimizers import RMSprop
from keras.callbacks import ModelCheckpoint, EarlyStopping

check_point = ModelCheckpoint("celebs.h5",
                             monitor = 'val_loss',
                             mode = 'min',
                             verbose = 1,
                             save_best_only = True)

early_stop = EarlyStopping(monitor = 'val_loss',
                          min_delta = 0,
                          patience = 3,
                          verbose = 1,
                          restore_best_weights = True)

callbacks = [check_point, early_stop]

train_images = 174
val_images = 30
epochs = 5
batch_size = 4

model.compile(optimizer = RMSprop(lr= 0.001),
              loss = 'categorical_crossentropy',
              metrics = ['accuracy'])

history = model.fit_generator(generated_train_images,
                              steps_per_epoch = train_images // batch_size,
                              epochs = epochs,
                              callbacks = callbacks,
                              validation_data = generated_val_images,
                              validation_steps = val_images // batch_size)

from keras.models import load_model
model = load_model('celebs.h5')

from google.colab.patches import cv2_imshow
import numpy as np
import cv2
import os
#from os import listdir
#from os.path import isfile ,isdir ,join

celebs_list = ['Shahrukh Khan','Saif Ali Khan']

celebs_dict = { 'n0':'Shahrukh Khan',
                'n1':'Saif Ali Khan'
              }

def getTestImage(path):
  class_folders = list(filter(lambda x: os.path.isdir(os.path.join(path,x)),os.listdir(path)))
  folder_index = np.random.randint(0,len(class_folders))
  random_folder_name = class_folders[folder_index]
  print('Actual Class :',celebs_dict[str(random_folder_name)])
  folder_path = path + random_folder_name
  image_files = [file for file in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path,file))]
  image_index = np.random.randint(0,len(image_files))
  random_image_name = image_files[image_index]
  image_path = folder_path + "/"+ random_image_name
  return(cv2.imread(image_path))

def displayTestImage(image,category):
  celeb = celebs_list[category]
  white =[255,255,255]
  display_image = cv2.copyMakeBorder(image, 80 ,10,10,100, cv2.BORDER_CONSTANT,value = white)
  cv2.putText(display_image, celeb, (0,50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,0),2)
  cv2_imshow(display_image)



for i in range(0,10):
  image1 = getTestImage('/content/drive/My Drive/dataset/val/')
  image2 = image1.copy()
  image1 = cv2.resize(image1, None, fx = 0.5, fy = 0.5, interpolation = cv2.INTER_LINEAR )
  

  image2 = cv2.resize(image2, dsize = (224,224), interpolation = cv2.INTER_LINEAR)
  image2 = image2/255.
  image2 = image2.reshape(1,224,224,3)
  result = model.predict(image2, 1, verbose=0)
  result_index = int(np.argmax(result, axis = 1))

  displayTestImage(image1,result_index)
  cv2.waitKey(0)

cv2.destroyAllWindows